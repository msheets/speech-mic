<!--
Copyright (c) 2014 The Polymer Project Authors. All rights reserved.
This code may only be used under the BSD style license found at http://polymer.github.io/LICENSE.txt
The complete set of authors may be found at http://polymer.github.io/AUTHORS.txt
The complete set of contributors may be found at http://polymer.github.io/CONTRIBUTORS.txt
Code distributed by Google as part of the polymer project is also
subject to an additional IP rights grant found at http://polymer.github.io/PATENTS.txt
-->

<link rel="import" href="../polymer/polymer.html">
<link rel="import" href="../paper-fab/paper-fab.html">
<link rel="import" href="../iron-icons/av-icons.html">


<!--
The `speech-mic` element has a mic icon and tapping on the mic will start the 
speech recognition and invite the user to allow a page access to their
microphone.  Once the access is allowed the user can start talking to the
microphone and transcript will be recorded until the mic is tapped again to
stop the speech recognition.

Example:

    <input value="{{transcript}}">
    <speech-mic transcript="{{transcript}}"></speech-mic>

@element speech-mic
@homepage github.io
-->

<dom-module id="speech-mic">
  <template>
    <style is="custom-style">
      :host {
        display: inline-block;
        position: relative;
        cursor: pointer;
      
        --accent-color: var(--paper-red-500);
        --paper-fab-keyboard-focus-background: var(--accent-color); 

        /* NOTE: Both values are needed, since some phones require the value `transparent`. */
        -webkit-tap-highlight-color: rgba(0,0,0,0);
        -webkit-tap-highlight-color: transparent;
      }

      /* use a separate source so as to maintain FAB box-shadow */
      #pulseSource {
        border-radius: 50%;
        position: absolute;
        top: 0;
        left: 0;
        right: 0;
        bottom: 0;
      }

      :host[recognizing] #pulseSource{
        animation: pulse 1.5s ease infinite;
      }

      @keyframes pulse {
        0% {
          transform: scale(1);
          box-shadow: 0 0 0 0px rgba(255, 0, 0, 0.4);
        }
        99% {
          box-shadow: 0 0 0 30px rgba(255, 0, 0, 0.0);
        }
      }
    </style>

    <div id="pulseSource"></div>
    <paper-fab id="button" mini=[[mini]] icon="av:mic" toggles></paper-fab>

  </template>

  <script>
    (function() {
    
      var SUPPORTED_LANGS = ['af-ZA', 'id-ID', 'ms-MY', 'ca-ES', 'cs-CZ', 'de-DE', 'en-US', 'en-AU', 'en-CA', 'en-IN', 'en-NZ', 'en-ZA', 'en-GB', 'es-AR', 'es-BO', 'es-CL', 'es-CO', 'es-CR', 'es-EC', 'es-SV', 'es-ES', 'es-US', 'es-GT', 'es-HN', 'es-MX', 'es-NI', 'es-PA', 'es-PY', 'es-PE', 'es-PR', 'es-DO', 'es-UY', 'es-VE', 'eu-ES', 'fr-FR', 'gl-ES', 'hr_HR', 'zu-ZA', 'is-IS', 'it-IT', 'it-CH', 'hu-HU', 'nl-NL', 'nb-NO', 'pl-PL', 'pt-BR', 'pt-PT', 'ro-RO', 'sk-SK', 'fi-FI', 'sv-SE', 'tr-TR', 'bg-BG', 'ru-RU', 'sr-RS', 'ko-KR', 'zh-cmn-Hans-CN', 'cmn-Hans-CN', 'cmn-Hans-HK', 'cmn-Hant-TW', 'yue-Hant-HK', 'ja-JP', 'la'];
      

      Polymer({
        is: 'speech-mic',
        
        // Define public properties
        properties: {
          /**
           * Specifies the language of the speech synthesis for the utterance 
           */
          language: {
            type: String,
            value: 'en-US'
          },

          /**
           * Returns the current transcript string
           */
          finalTranscript: {
            type: String,
            value: ''
          },

          /* 
           * Returns the complete transcript string for the continuous recognition 
           */
          interimTranscript: {
            type: String,
            value: ''
          },

          recognizing: {
            type: Boolean,
            value: false,
            notify: false,
            reflectToAttribute: true
          },

          /**
           * Set this to true to style this is a "mini" FAB.
           */
          mini: {
            type: Boolean,
            value: false,
            reflectToAttribute: true
          },
        },

        listeners: {
          'tap': 'toggleRecognition'                        
        },
  
       ready: function() {
          if (window.hasOwnProperty('webkitSpeechRecognition')) {
            this.recognition = new webkitSpeechRecognition();

            this.recognition.continuous = true;
            this.recognition.interimResults = true;

            this.recognition.onstart = this._onStart.bind(this);
            this.recognition.onend = this._onEnd.bind(this);
            this.recognition.onresult = this._onResult.bind(this);
            this.recognition.onerror = this._onError.bind(this);
            
            // this.recognition.lang = this.language;
          } else {
            console.log("Speech recognition not supported.")
            this.style.display = 'none'; // TODO: improve warning
          }
        },
      
      languageChanged: function() {
        if (!this.recognition) {
          return;
        }
        this.recognition.lang = this.findSupportedLang(this.language);
      },
      
      findSupportedLang: function(l) {
        if (SUPPORTED_LANGS.indexOf(l) >= 0) {
          return l;
        } else {
          var ll = l.substring(0, 2);
          for (var i = 0, sl; sl = SUPPORTED_LANGS[i]; i++) {
            if (sl.indexOf(ll) == 0) {
              return sl;
            }
          }
        }
      },
      
      toggleRecognition: function() {
        if (!this.recognition) {
          return;
        }
        if (this.recognizing) {
          this.recognition.stop();
        } else {
          this.recognition.start();
        }
      },
      
      _onStart: function(e) {
        this.recognizing = true;
        this.$.button.elevation = "0";
        this.updateStyles();

      },
      
      _onEnd: function() {
        this.recognizing = false;
        this.$.button.elevation = "1";
        this.updateStyles();
      },
      
      _onStop: function() {
        this.recognition && this.recognition.stop();
      },
      
      _onResult: function(e) {
        this.interimTranscript= '';

        for (var i = event.resultIndex; i < event.results.length; ++i) {
          if (event.results[i].isFinal) {
            this.finalTranscript += event.results[i][0].transcript;
          } else {
            this.interimTranscript += event.results[i][0].transcript;
          }
        }
        this.fire('speech-mic-result', {
          results: e.results,
          finalTranscript: this.finalTranscript,
          interimTranscript: this.interimTranscript,
        });
      },
      
      _onError: function(e) {
        console.log(e);
      }

      /**
       * Fired when the speech recognizer returns a result.
       * 
       * @event speech-mic-result
       * @param {Object} detail
       *   @param {Object} detail.results SpeechRecognitionEvent object
       *   @param {Object} detail.finalTranscript The portion of the transcript that is finalized
       *   @param {Object} detail.interimTranscript The unfinalize portion of the transcript (used for
       *                                            continuous transcription)
       */
    });
  })();
</script>
</dom-module>
